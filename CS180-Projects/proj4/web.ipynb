{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"font-style: italic;\">[Auto]Stitching Photo Mosaics</h1>\n",
    "</div>\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/intro.jpg\" alt=\"Image 1\" style=\"width: 600px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***IMAGE WARPING and MOSAICING***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;The goal of this assignment is to explore different aspects of image warping through a practical and exciting applicationâ€”image mosaicing. In this project, I worked with photographs and created image mosaics by performing several key operations: image registration, projective warping and blending. Along the way, I learned how to compute homographies and used them to warp and align images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Recover Homographies***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Before warping the images into alignment, we need to recover the parameters of the transformation between each pair of images. In our case, the transformation is a homography: $\\mathbf{p^{\\prime}} = \\mathbf{Hp}$, where $\\mathbf{H}$ is a $3 \\times 3$ matrix with $8$ degrees of freedom (lower right corner is a scaling factor and can be set to $1$), that is\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x^{\\prime} \\\\\n",
    "y^{\\prime} \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "a & b & c \\\\\n",
    "d & e & f \\\\\n",
    "g & h & 1 \\\\\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "&emsp;&emsp;We could convert the equation above into th form of $\\mathbf{Ah} = \\mathbf{b}$, where $\\mathbf{h} = \\begin{bmatrix}\n",
    "a, b, c, d, e, f, g, h \\\\\n",
    "\\end{bmatrix}^{\\top}$. Then, for each pair of corresponding points, we have\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x_{i} & y_{i} & 1 & 0 & 0 & 0 & -x_{i}x_{i}^{\\prime} & -y_{i}x_{i}^{\\prime} \\\\\n",
    "0 & 0 & 0 & x_{i} & y_{i} & 1 & -x_{i}y_{i}^{\\prime} & -y_{i}y_{i}^{\\prime} \\\\\n",
    "\\end{bmatrix} \\cdot \\mathbf{h} = \\begin{bmatrix}\n",
    "x_{i}^{\\prime} \\\\\n",
    "y_{i}^{\\prime} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "&emsp;&emsp;To solve this, at least 4 pairs of corresponding points should be chosen. However, with only four points, the homography recovery will be very unstable and prone to noise. Therefore more than 4 correspondences should be provided producing an overdetermined system which should be solved using least-squares. Then, we could solve this using least-squares,\n",
    "$$\n",
    "\\mathbf{h} = \\arg\\min_{\\mathbf{h}} \\|\\mathbf{Ah} - \\mathbf{b}\\|^{2} = (\\mathbf{A}^{\\top}\\mathbf{A})^{-1}\\mathbf{A}^{\\top}\\mathbf{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Warp the Images***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;To ensure that the warped image will not go beyond the canvas, I first add borders with 0, i.e. black borders, to them and modify the position of the corresponding points as well, which should be related to the size of border added. With the homography matrix $\\mathbf{H}$, I could warp the source image to match the view direction of the target image.\n",
    "\n",
    "&emsp;&emsp;I choose to perform inverse warping. I compute the corresponding coordinates of pixels in the source image of each pixels in the destination image, which could be calculated according to the homography matrix $\\mathbf{H}$. Then, I use `scipy.interpolate.griddata` to perform interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Image Rectification***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Here are two examples of image rectification.\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Original Phone</p>\n",
    "        <img src=\"./media/phone_lean.jpg\" alt=\"Image 1\" style=\"height: 260px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Rectifies Phone</p>\n",
    "        <img src=\"./media/phone.jpg\" alt=\"Image 2\" style=\"height: 260px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Original Shoe Box</p>\n",
    "        <img src=\"./media/puma_lean.jpg\" alt=\"Image 1\" style=\"height: 260px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Rectified Shoe Box</p>\n",
    "        <img src=\"./media/puma.jpg\" alt=\"Image 2\" style=\"height: 260px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Blend the images into a mosaic***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;To blend the images into a mosaic, I choose the central image as a target for the other images to warp to. Once they are warpped, build alpha mask for them following the logic below:\n",
    "$$\n",
    "    \\alpha = \\text{logical}(\\text{dtrans}1 > \\text{dtrans}2)\n",
    "$$\n",
    "$$\n",
    "    \\alpha = \\text{blurred}\n",
    "$$\n",
    "&emsp;&emsp;That is, set the part where transformed distance of image 1 is larger as $1$, and then blur the mask.\n",
    "\n",
    "&emsp;&emsp;Then I could blend all image together with Laplacian stacks to make a mosaic. I also tried Laplacian pyramids as well, but the results of stack are better. I use alpha mask to blend images and the target image. To blend the bended images together, I just use the trivial mask that divide the image into left and right part since the target is set to center.\n",
    "\n",
    "&emsp;&emsp;The results are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Li Ka Shing Center***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;These are images taken near the Li Ka Shing Center.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/pts_building.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Warp them into the direction of central image:\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/warped_building.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Blend them together,\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/mosaic_building.jpg\" alt=\"Image 1\" style=\"width: 400px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Street***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;These are images of a student housing at Hearst Street.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/pts_street.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Warp them into the direction of central image:\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/warped_street.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Blend them together,\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/mosaic_street.jpg\" alt=\"Image 1\" style=\"width: 400px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Valley Life Sciences Building***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;I took these cool images at Valley Life Sciences Building.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/pts_model.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Warp them into the direction of central image:\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/warped_model.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Blend them together,\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/mosaic_model.jpg\" alt=\"Image 1\" style=\"width: 400px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Feature Matching and Autostitching***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;I manually selected the corresponding points in the previous part. In this section, I developed a system to automatically identify matching points between a pair of images and then use these key points to warp and create a mosaic, similar to the previous method. This will consist of the following steps:\n",
    "- Detecting corner features in an image.\n",
    "- Extracting a Feature Descriptor for each feature point.\n",
    "- Matching these feature descriptors between two images.\n",
    "- Use a robust method (RANSAC) to compute a homography.\n",
    "- Produce a mosaic.\n",
    "\n",
    "&emsp;&emsp;I used the images taken at Valley Life Sciences Building as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Start with Harris Interest Point Detector***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;For this part, I just used the sample code for implementing Harris corners detector. The `get_harris_corners` function is based on the Harris corner detection algorithm, which identifies corners by analyzing how the intensity values in a local neighborhood vary. The key idea is to detect points in an image where small shifts in any direction result in significant intensity changes.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/harris.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Implement Adaptive Non-Maximal Suppression***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Once we have identified the Harris corners, we can apply Adaptive Non-Maximal Suppression to filter the potential keypoints, retaining only those that correspond to strong corners and are approximately evenly distributed across the image. The algorithm assigns every key point an $r$ score as follows, where the function $f$ corresponds to the Harris response:\n",
    "$$\n",
    "    r_{i} = \\mathop{\\min}\\limits_{j}|\\mathbf{x}_{i} - \\mathbf{x}_{j}|, \\text{s.t.} f(\\mathbf{x}_{i}) < c_{\\text{robust}} f(\\mathbf{x}_{j}), \\mathbf{x}_{j} \\in \\mathcal{I}\n",
    "$$\n",
    "where $\\mathbf{x}_{i}$ is a 2D interest point image location, and $\\mathcal{I}$ is the set of all interest point locations.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/anms.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Implement Feature Descriptor Extraction***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;To effectively match feature points across images, it's essential to gather more than just single pixel information. This requires the use of feature descriptors that encapsulate local details about the image, ensuring consistency across various images of the same underlying scene. To achieve this, I extracted a 40x40 window centered on each feature point, which was then downsampled into an 8x8 patch. This process included normalization and mean subtraction to enhance robustness.\n",
    "\n",
    "&emsp;&emsp;Here is an example feature descriptor: \n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/features.jpg\" alt=\"Image 1\" style=\"width: 600px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Implement Feature Matching***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;To match feature descriptors, I employ ***Lowe's trick***. First, I compute the closest (1-NN) and second-closest (2-NN) matches for each feature patch. Then, the ratio between the distances of the 1-NN and 2-NN is calculated. If this ratio falls below a specified threshold, the 1-NN is considered a valid match.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/match.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;We could observe that the result is not good enough in this example since there are still some bad matches. Thus, consider Random Sample Consensus (RANSAC) for robust homography estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***4-point Random Sample Consensus (RANSAC)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Random Sample Consensus (RANSAC) helps minimize the influence of outliers on the resulting model. I followed the steps mentioned in course slides, here is a RANSAC loop:\n",
    "1. Select four feature pairs (at random).\n",
    "2. Compute homography $H$ (exact).\n",
    "3. Compute *inliers* where $dist(p_{i}', Hp_{i}) < \\varepsilon$.\n",
    "4. Keep largest set of inliers.\n",
    "5. Re-compute least-squares $H$ estimate on all of the inliers.\n",
    "\n",
    "&emsp;&emsp;Here is an example of applying RANSAC for automatically stitched results. We could notice that the algorithm successfully removes the poor matches.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/ransac_inliers_model.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Then we could create the mosaic:\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Automatically Stitched Result</p>\n",
    "        <img src=\"./media/ransac_model.jpg\" alt=\"Image 1\" style=\"height: 300px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Manually Stitched Result</p>\n",
    "        <img src=\"./media/manual_model.jpg\" alt=\"Image 2\" style=\"height: 300px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Comparing the manually and automatically stitched results, we could observe that the automatically one performs better on some details, such as the border of the display cabinet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***More Examples***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;I also considered some interesting samples I did not show you in the previous part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Halloween Decoration***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Here are some sonderful Halloween decoration! Both manually and automatically stitched results perform well.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Automatically Stitched Result</p>\n",
    "        <img src=\"./media/ransac_decoration.jpg\" alt=\"Image 1\" style=\"height: 240px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Manually Stitched Result</p>\n",
    "        <img src=\"./media/manual_decoration.jpg\" alt=\"Image 2\" style=\"height: 240px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Forest***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;This is the most amazing example! For these images of forest, it is difficult for me to manually select the corresponding points. However, the automatical method could easily figure out them even with a tiny threshold!\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <img src=\"./media/ransac_inliers_forest.jpg\" alt=\"Image 1\" style=\"width: 800px;\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "&emsp;&emsp;Once again, both manually and automatically stitched results perform well.\n",
    "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Automatically Stitched Result</p>\n",
    "        <img src=\"./media/ransac_forest.jpg\" alt=\"Image 1\" style=\"height: 300px;\">\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "        <p style=\"font-weight: bold;\">Manually Stitched Result</p>\n",
    "        <img src=\"./media/manual_forest.jpg\" alt=\"Image 2\" style=\"height: 300px;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Cool Stuff I Learnt***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;My favorite parts in this project were the Image Rectification and Autostitching sections. I was thrilled to see how homography could smoothly transform images with significant distortion back into the correct alignment. Autostitching made it incredibly easy to find corresponding points between two images, which was a great experience for me. At the same time, I applied knowledge from previous projects, like the Laplacian pyramid algorithm, which made me realize that Iâ€™m systematically building my understanding of computer vision. Last but not least, I discovered just how interesting and crucial linear algebra is in these applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
